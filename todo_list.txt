1) Think about the most suited ML algo (Random Forest for accuracy, maybe DecisionTreeRegressor? pg. 13 AML1920_Adv_Lecture_1, maybe a Hard Voting Classifier? pg. 38 AML1920_Adv_Lecture_1, why not NN like MLPClassifier?)
2) Define features - DONE (tipologia, genere, bagno, cucina, salotto, balcone, zona)
3) Define target - DONE (euro)
4) Adequate text features to numerical ones
5) Feature scaling (pg. 34 AML1920_Basic_Lecture2)
6) Mean normalisation (pg.36 AML1920_Basic_Lecture2)
7) Perform the data preparation (Copy of AML_1-5_DataPreparation_LoadDataset.ipynb Drive)
8) TVT splitting (pg. 32 AML1920_Basic_Lecture5) or k-fold Cross-Validation (pg. 44 AML1920_Adv_Lecture_5)
9) Look for correlations (pg. 29 AML1920_Adv_Lecture_5)
10) Implement ROC curve and AUC maybe lately? (pag. 4 ALM1920_Basic_Lecture7)
11) Implement bagging and/or pasting? (pg. 42 AML1920_Adv_Lecture_1)
12) Fine tuning with Grid Search/Randomised Search maybe? (pg. 51 AML1920_Adv_Lecture_5)
13) Evaluate the system (pg. 56 AML1920_Adv_Lecture_5)
14) Add cool widgets to interact with (https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html)
15) Possible pre-pruning if using a DT, also with GridSearchCV with Random Forest?